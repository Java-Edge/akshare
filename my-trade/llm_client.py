#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
æœ¬åœ°å¤§æ¨¡å‹å®¢æˆ·ç«¯
è¿æ¥ LM Studio æä¾›çš„æœ¬åœ°å¤§æ¨¡å‹æœåŠ¡ï¼Œæä¾›æŠ•èµ„å»ºè®®åˆ†æ

ä½œè€…: JavaEdge
æ—¥æœŸ: 2025-01-25
"""

import requests
import json
from typing import Dict, Optional
import time


class LocalLLMClient:
    """æœ¬åœ°å¤§æ¨¡å‹å®¢æˆ·ç«¯"""

    def __init__(self, api_url: str = "http://10.56.88.6:1234/v1/chat/completions",
                 model: str = "google/gemma-3-27b",
                 timeout: int = 120):
        """
        åˆå§‹åŒ–æœ¬åœ°LLMå®¢æˆ·ç«¯

        :param api_url: æœ¬åœ°æ¨¡å‹APIåœ°å€
        :param model: æ¨¡å‹åç§°
        :param timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.api_url = api_url
        self.model = model
        self.timeout = timeout
        self._test_connection()

    def _test_connection(self):
        """æµ‹è¯•ä¸æœ¬åœ°æ¨¡å‹çš„è¿æ¥"""
        try:
            response = requests.get(
                self.api_url.replace('/v1/chat/completions', '/v1/models'),
                timeout=5
            )
            if response.status_code == 200:
                print("âœ… æœ¬åœ°å¤§æ¨¡å‹è¿æ¥æˆåŠŸ")
            else:
                print(f"âš ï¸  æœ¬åœ°æ¨¡å‹å“åº”å¼‚å¸¸: {response.status_code}")
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è¿æ¥åˆ°æœ¬åœ°æ¨¡å‹: {e}")
            print("   å°†ä½¿ç”¨åŸºç¡€åˆ†ææ¨¡å¼")

    def chat(self, messages: list, temperature: float = 0.7,
             max_tokens: int = -1, stream: bool = False) -> Optional[Dict]:
        """
        å‘é€èŠå¤©è¯·æ±‚åˆ°æœ¬åœ°æ¨¡å‹

        :param messages: æ¶ˆæ¯åˆ—è¡¨
        :param temperature: æ¸©åº¦å‚æ•°
        :param max_tokens: æœ€å¤§tokenæ•°
        :param stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
        :return: æ¨¡å‹å“åº”å­—å…¸
        """
        request_data = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": stream
        }

        try:
            response = requests.post(
                url=self.api_url,
                headers={"Content-Type": "application/json"},
                data=json.dumps(request_data),
                timeout=self.timeout
            )

            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    return result
                else:
                    print("âŒ æ¨¡å‹å“åº”æ ¼å¼å¼‚å¸¸")
                    return None
            else:
                print(f"âŒ æ¨¡å‹è¯·æ±‚å¤±è´¥: {response.status_code}")
                print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
                return None

        except requests.exceptions.Timeout:
            print("âŒ æ¨¡å‹è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æœåŠ¡çŠ¶æ€")
            return None
        except requests.exceptions.ConnectionError:
            print("âŒ æ— æ³•è¿æ¥åˆ°æœ¬åœ°æ¨¡å‹æœåŠ¡")
            return None
        except Exception as e:
            print(f"âŒ è¯·æ±‚å‘ç”Ÿé”™è¯¯: {e}")
            return None

    def get_response_content(self, response: Dict) -> str:
        """
        ä»å“åº”ä¸­æå–å†…å®¹

        :param response: æ¨¡å‹å“åº”å­—å…¸
        :return: å“åº”å†…å®¹æ–‡æœ¬
        """
        if not response:
            return ""

        try:
            return response['choices'][0]['message']['content']
        except (KeyError, IndexError):
            return ""

    def analyze_investment(self, market_data: Dict, principles: str) -> str:
        """
        ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡ŒæŠ•èµ„åˆ†æ

        :param market_data: å¸‚åœºæ•°æ®å­—å…¸
        :param principles: æŠ•èµ„åŸåˆ™æ–‡æœ¬
        :return: åˆ†æç»“æœ
        """
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ•èµ„é¡¾é—®ï¼Œç²¾é€šæŠ€æœ¯åˆ†æå’Œå¸‚åœºç ”åˆ¤ã€‚

ä½ å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹æŠ•èµ„åŸåˆ™å’Œç­–ç•¥ï¼š

{principles}

è¯·åŸºäºä»¥ä¸ŠåŸåˆ™ï¼Œç»“åˆæä¾›çš„å¸‚åœºæ•°æ®ï¼Œç»™å‡ºä¸“ä¸šçš„æŠ•èµ„å»ºè®®ã€‚
ä½ çš„å»ºè®®å¿…é¡»ï¼š
1. å®Œå…¨ç¬¦åˆç”¨æˆ·çš„æŠ•èµ„åŸåˆ™
2. åŸºäºæŠ€æœ¯æŒ‡æ ‡å’Œå¸‚åœºæ•°æ®
3. è€ƒè™‘é£é™©æ§åˆ¶å’Œä»“ä½ç®¡ç†
4. ç»™å‡ºæ˜ç¡®çš„æ“ä½œå»ºè®®ï¼ˆä¹°å…¥/æŒæœ‰/å–å‡ºï¼‰
5. è§£é‡Šå†³ç­–ç†ç”±

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šä¸”ç®€æ´ã€‚"""

        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹å¸‚åœºæ•°æ®å¹¶ç»™å‡ºæŠ•èµ„å»ºè®®ï¼š

ã€åŸºé‡‘ä»£ç ã€‘{market_data.get('fund_code', 'æœªçŸ¥')}
ã€åˆ†ææ—¥æœŸã€‘{market_data.get('analysis_date', 'æœªçŸ¥')}

ã€å¸‚åœºçŠ¶æ€ã€‘
- æœ€æ–°ä»·æ ¼: {market_data['statistics']['latest_price']:.4f}
- æœ€æ–°æ¶¨è·Œ: {market_data['statistics']['latest_change']:+.2f}%
- è¿‘æœŸæ€»æ”¶ç›Š: {market_data['statistics']['total_return']:+.2f}%
- æ—¥å‡æ”¶ç›Š: {market_data['statistics']['avg_daily_return']:+.2f}%
- æ³¢åŠ¨ç‡: {market_data['statistics']['volatility']:.2f}%
- èƒœç‡: {market_data['statistics']['win_rate']:.1f}%

ã€æŠ€æœ¯æŒ‡æ ‡ã€‘
- RSI(14): {market_data['technical']['rsi']:.1f}
- 5æ—¥åŠ¨é‡: {market_data['technical']['momentum_5d']:+.2f}%
- 10æ—¥åŠ¨é‡: {market_data['technical']['momentum_10d']:+.2f}%
- ç›¸å¯¹MA5: {market_data['technical']['current_vs_ma5']:+.2f}%
- ç›¸å¯¹MA10: {market_data['technical']['current_vs_ma10']:+.2f}%
- ç›¸å¯¹MA20: {market_data['technical']['current_vs_ma20']:+.2f}%

ã€è¶‹åŠ¿åˆ†æã€‘
- æ–¹å‘: {market_data['trend']['direction']}
- å¼ºåº¦: {market_data['trend']['strength']}
- åŠ¨é‡: {market_data['trend']['momentum']:.1%}
- è¿‘{market_data['trend']['recent_days']}å¤©: {market_data['trend']['up_days']}æ¶¨ {market_data['trend']['down_days']}è·Œ

ã€é£é™©è¯„ä¼°ã€‘
- é£é™©ç­‰çº§: {market_data['risk']['level']}
- RSIçŠ¶æ€: {market_data['risk']['rsi_status']}
- è¯´æ˜: {market_data['risk']['description']}

ã€åŸºç¡€äº¤æ˜“ä¿¡å·ã€‘
- ä¿¡å·: {market_data['signal']['signal']}
- è¯„åˆ†: {market_data['signal']['score']:.1f}
- ç½®ä¿¡åº¦: {market_data['signal']['confidence']:.1f}%

è¯·åŸºäºä»¥ä¸Šæ•°æ®å’Œä½ çš„æŠ•èµ„åŸåˆ™ï¼Œç»™å‡ºï¼š
1. æœ€ç»ˆçš„æ“ä½œå»ºè®®ï¼ˆå¼ºçƒˆä¹°å…¥/ä¹°å…¥/æŒæœ‰/å–å‡º/å¼ºçƒˆå–å‡ºï¼‰
2. å»ºè®®çš„ä»“ä½æ¯”ä¾‹ï¼ˆ0-100%ï¼‰
3. è¯¦ç»†çš„å†³ç­–ç†ç”±ï¼ˆè‡³å°‘3ç‚¹ï¼‰
4. é£é™©æç¤º
5. æ“ä½œè®¡åˆ’ï¼ˆä»€ä¹ˆæ—¶å€™ä¹°/å–ï¼Œå¦‚ä½•åˆ†æ‰¹ç­‰ï¼‰

è¯·ç¡®ä¿å»ºè®®å®Œå…¨ç¬¦åˆä½ çš„æŠ•èµ„åŸåˆ™ï¼Œç‰¹åˆ«æ˜¯å…³äºåœºå†…å¤–åŸºé‡‘é€‰æ‹©ã€æ­¢ç›ˆç­–ç•¥ã€æ¿å—é…ç½®ç­‰æ–¹é¢çš„åŸåˆ™ã€‚"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        print("\nğŸ¤– æ­£åœ¨è°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æ...")
        print("â³ åˆ†æä¸­ï¼Œè¯·ç¨å€™...")

        start_time = time.time()
        response = self.chat(messages, temperature=0.3)  # è¾ƒä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„å»ºè®®
        elapsed_time = time.time() - start_time

        if response:
            content = self.get_response_content(response)
            if content:
                print(f"âœ… åˆ†æå®Œæˆï¼ˆè€—æ—¶ {elapsed_time:.1f} ç§’ï¼‰\n")
                return content
            else:
                print("âŒ æœªèƒ½è·å–æ¨¡å‹åˆ†æç»“æœ")
                return ""
        else:
            print("âŒ æ¨¡å‹åˆ†æå¤±è´¥")
            return ""


# å…¨å±€å®¢æˆ·ç«¯å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_llm_client = None


def get_llm_client() -> Optional[LocalLLMClient]:
    """è·å–å…¨å±€LLMå®¢æˆ·ç«¯å®ä¾‹"""
    global _llm_client
    if _llm_client is None:
        try:
            _llm_client = LocalLLMClient()
        except Exception as e:
            print(f"âš ï¸  åˆå§‹åŒ–æœ¬åœ°æ¨¡å‹å®¢æˆ·ç«¯å¤±è´¥: {e}")
            return None
    return _llm_client


def test_llm_client():
    """æµ‹è¯•LLMå®¢æˆ·ç«¯"""
    print("=" * 80)
    print("æµ‹è¯•æœ¬åœ°å¤§æ¨¡å‹å®¢æˆ·ç«¯")
    print("=" * 80)

    client = LocalLLMClient()

    # ç®€å•æµ‹è¯•
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"},
        {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä»€ä¹ˆæ˜¯QDIIåŸºé‡‘ï¼Ÿ"}
    ]

    response = client.chat(messages)
    if response:
        content = client.get_response_content(response)
        print("\næ¨¡å‹å›ç­”:")
        print(content)
        print("\nâœ… æµ‹è¯•æˆåŠŸï¼")
        return True
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    test_llm_client()
