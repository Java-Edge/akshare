#!/usr/bin/env python
# -*- coding:utf-8 -*-
"""
QDIIåŸºé‡‘åˆ†æå·¥å…·
ä¼ å…¥æŒ‡å®šçš„QDIIåŸºé‡‘ä»£ç ï¼ŒæŸ¥è¯¢è¿‘30ä¸ªäº¤æ˜“æ—¥çš„æ¶¨è·Œå¹…æ•°æ®å¹¶ç»˜åˆ¶æŠ˜çº¿å›¾
"""

import akshare as ak
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import matplotlib.font_manager as fm
import pymysql
from pymysql import Error
import database_config
from investment_advisor import quick_advice

fund_code = "513100"  # å¯ä»¥æ›¿æ¢ä¸ºå…¶ä»–QDIIåŸºé‡‘ä»£ç 
days = 30  # åˆ†ææœ€è¿‘30ä¸ªäº¤æ˜“æ—¥

def query_from_database(fund_code: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ä»æ•°æ®åº“æŸ¥è¯¢åŸºé‡‘æ•°æ®

    :param fund_code: åŸºé‡‘ä»£ç 
    :param start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
    :param end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
    :return: åŒ…å«åŸºé‡‘æ•°æ®çš„DataFrame
    """
    connection = None
    try:
        connection = pymysql.connect(**database_config.MYSQL_CONFIG)
        with connection.cursor() as cursor:
            cursor.execute(database_config.QUERY_DATA_SQL, (fund_code, start_date, end_date))
            results = cursor.fetchall()

            if results:
                # è·å–åˆ—å
                column_names = [desc[0] for desc in cursor.description]
                df = pd.DataFrame(results, columns=column_names)

                # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
                if 'æ—¥æœŸ' in df.columns:
                    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])

                # å°†æ•°å€¼åˆ—ä» Decimal è½¬æ¢ä¸º float
                numeric_columns = ['å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ¶¨è·Œå¹…', 'æˆäº¤é¢']
                for col in numeric_columns:
                    if col in df.columns:
                        df[col] = df[col].astype(float)

                # å°†æˆäº¤é‡è½¬æ¢ä¸ºæ•´æ•°
                if 'æˆäº¤é‡' in df.columns:
                    df['æˆäº¤é‡'] = df['æˆäº¤é‡'].astype(int)

                return df
            else:
                return pd.DataFrame()

    except Exception as e:
        print(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
        return pd.DataFrame()
    finally:
        if connection and connection.open:
            connection.close()

def get_missing_dates(existing_dates, all_dates):
    """
    è·å–ç¼ºå¤±çš„æ—¥æœŸ

    :param existing_dates: å·²å­˜åœ¨çš„æ—¥æœŸåˆ—è¡¨
    :param all_dates: æ‰€æœ‰éœ€è¦çš„æ—¥æœŸåˆ—è¡¨
    :return: ç¼ºå¤±çš„æ—¥æœŸåˆ—è¡¨
    """
    existing_date_set = set(existing_dates)
    return [date for date in all_dates if date not in existing_date_set]

def get_qdii_fund_data(fund_code: str, days: int = 30) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    è·å–QDIIåŸºé‡‘è¿‘Nä¸ªäº¤æ˜“æ—¥çš„æ¶¨è·Œå¹…æ•°æ®ï¼ˆæ™ºèƒ½è·å–ï¼šå…ˆæŸ¥æ•°æ®åº“ï¼Œå†è¡¥å…¨ç¼ºå¤±æ•°æ®ï¼‰

    :param fund_code: QDIIåŸºé‡‘ä»£ç 
    :param days: äº¤æ˜“æ—¥å¤©æ•°
    :return: (å®Œæ•´æ•°æ®DataFrame, æ–°è·å–çš„æ•°æ®DataFrame)
    """
    try:
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().date()
        start_date = (end_date - timedelta(days=days*2)).strftime("%Y-%m-%d")
        end_date_str = end_date.strftime("%Y-%m-%d")

        print(f"ğŸ“Š å…ˆä»æ•°æ®åº“æŸ¥è¯¢æ•°æ® ({start_date} åˆ° {end_date_str})...")

        # 1. å…ˆä»æ•°æ®åº“æŸ¥è¯¢æ•°æ®
        db_df = query_from_database(fund_code, start_date, end_date_str)

        if not db_df.empty:
            print(f"âœ… ä»æ•°æ®åº“è·å–åˆ° {len(db_df)} æ¡å†å²æ•°æ®")

        # 2. è®¡ç®—éœ€è¦çš„æ‰€æœ‰äº¤æ˜“æ—¥æ—¥æœŸ
        all_required_dates = pd.date_range(end=end_date, periods=days, freq='B')  # å·¥ä½œæ—¥

        if not db_df.empty:
            # æ•°æ®åº“è¿”å›çš„æ˜¯ä¸­æ–‡åˆ—å
            date_col = 'æ—¥æœŸ'

            # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯ datetime ç±»å‹
            if db_df[date_col].dtype == 'object':
                db_df[date_col] = pd.to_datetime(db_df[date_col])

            # 3. æ£€æŸ¥å“ªäº›æ—¥æœŸåœ¨æ•°æ®åº“ä¸­ç¼ºå¤±
            existing_dates = set(db_df[date_col].dt.date)
            missing_dates = [date for date in all_required_dates if date.date() not in existing_dates]

            if missing_dates:
                print(f"ğŸ“ å‘ç° {len(missing_dates)} ä¸ªç¼ºå¤±äº¤æ˜“æ—¥ï¼Œæ­£åœ¨ä»APIè·å–...")
                # 4. è·å–ç¼ºå¤±æ—¥æœŸçš„æ•°æ®
                missing_start = missing_dates[0].strftime("%Y%m%d")
                missing_end = missing_dates[-1].strftime("%Y%m%d")

                api_df = ak.fund_etf_hist_em(
                    symbol=fund_code,
                    period="daily",
                    start_date=missing_start,
                    end_date=missing_end,
                    adjust=""
                )

                if not api_df.empty:
                    api_df['æ—¥æœŸ'] = pd.to_datetime(api_df['æ—¥æœŸ'])
                    # 5. åˆå¹¶æ•°æ®åº“æ•°æ®å’ŒAPIæ•°æ®ï¼ˆéƒ½ä½¿ç”¨ä¸­æ–‡åˆ—åï¼‰
                    combined_df = pd.concat([db_df, api_df], ignore_index=True)
                    # å»é‡å¹¶æ’åº
                    combined_df = combined_df.drop_duplicates('æ—¥æœŸ').sort_values('æ—¥æœŸ', ascending=False).head(days)
                    print(f"âœ… æˆåŠŸåˆå¹¶æ•°æ®åº“å’ŒAPIæ•°æ®ï¼Œæ€»è®¡ {len(combined_df)} æ¡æ•°æ®")
                    # è¿”å›å®Œæ•´æ•°æ®å’Œæ–°è·å–çš„APIæ•°æ®
                    return combined_df.reset_index(drop=True), api_df.reset_index(drop=True)
                else:
                    print("âš ï¸  APIæœªè¿”å›ç¼ºå¤±æ—¥æœŸæ•°æ®ï¼Œä½¿ç”¨æ•°æ®åº“ç°æœ‰æ•°æ®")
                    # è¿”å›æ•°æ®åº“æ•°æ®ï¼Œæ–°æ•°æ®ä¸ºç©º
                    return db_df.sort_values('æ—¥æœŸ', ascending=False).head(days).reset_index(drop=True), pd.DataFrame()
            else:
                print("âœ… æ•°æ®åº“å·²åŒ…å«æ‰€æœ‰éœ€è¦çš„æ•°æ®")
                # è¿”å›æ•°æ®åº“æ•°æ®ï¼Œæ–°æ•°æ®ä¸ºç©º
                return db_df.sort_values('æ—¥æœŸ', ascending=False).head(days).reset_index(drop=True), pd.DataFrame()
        else:
            # æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®ï¼Œå®Œå…¨ä»APIè·å–
            print("ğŸ“¡ æ•°æ®åº“ä¸­æ— æ•°æ®ï¼Œä»APIè·å–å®Œæ•´æ•°æ®...")
            start_date_api = (end_date - timedelta(days=days*2)).strftime("%Y%m%d")
            end_date_api = end_date.strftime("%Y%m%d")

            df = ak.fund_etf_hist_em(
                symbol=fund_code,
                period="daily",
                start_date=start_date_api,
                end_date=end_date_api,
                adjust=""
            )

            if df.empty:
                raise ValueError(f"æœªæ‰¾åˆ°åŸºé‡‘ä»£ç  {fund_code} çš„å†å²æ•°æ®")

            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
            df = df.sort_values('æ—¥æœŸ', ascending=False).head(days)
            # è¿”å›å®Œæ•´æ•°æ®ï¼Œæ–°æ•°æ®å°±æ˜¯å®Œæ•´æ•°æ®ï¼ˆå› ä¸ºæ•°æ®åº“ä¸ºç©ºï¼‰
            return df.reset_index(drop=True), df.reset_index(drop=True)

    except Exception as e:
        print(f"âŒ æ•°æ®è·å–å¤±è´¥: {e}")
        print("ğŸ’¡ æ­£åœ¨å°è¯•ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºåŠŸèƒ½...")
        mock_df = generate_mock_data(fund_code, days)
        # è¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼Œæ–°æ•°æ®ä¸ºç©ºï¼ˆæ¨¡æ‹Ÿæ•°æ®ä¸ä¿å­˜ï¼‰
        return mock_df, pd.DataFrame()

def generate_mock_data(fund_code: str, days: int = 30) -> pd.DataFrame:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿçš„QDIIåŸºé‡‘æ•°æ®ç”¨äºæ¼”ç¤º

    :param fund_code: åŸºé‡‘ä»£ç 
    :param days: å¤©æ•°
    :return: æ¨¡æ‹Ÿæ•°æ®DataFrame
    """
    import numpy as np

    # ç”Ÿæˆæ—¥æœŸ
    dates = pd.date_range(end=datetime.now(), periods=days, freq='B')  # å·¥ä½œæ—¥

    # ç”Ÿæˆæ¨¡æ‹Ÿçš„æ¶¨è·Œå¹…æ•°æ® (-3% åˆ° +5% ä¹‹é—´)
    np.random.seed(42)  # å›ºå®šéšæœºç§å­ä»¥ä¾¿é‡ç°
    changes = np.random.uniform(-3, 5, days)

    # ç”Ÿæˆæ”¶ç›˜ä»·ï¼ˆä»100å¼€å§‹ï¼‰
    close_prices = [100]
    for change in changes:
        close_prices.append(close_prices[-1] * (1 + change/100))
    close_prices = close_prices[1:]  # å»æ‰åˆå§‹å€¼

    df = pd.DataFrame({
        'æ—¥æœŸ': dates,
        'å¼€ç›˜': [p * (1 + np.random.uniform(-0.01, 0.01)) for p in close_prices],
        'æ”¶ç›˜': close_prices,
        'æœ€é«˜': [p * (1 + np.random.uniform(0, 0.02)) for p in close_prices],
        'æœ€ä½': [p * (1 - np.random.uniform(0, 0.02)) for p in close_prices],
        'æ¶¨è·Œå¹…': changes,
        'æˆäº¤é‡': np.random.randint(100000, 500000, days),
        'æˆäº¤é¢': [v * p for v, p in zip(np.random.randint(100000, 500000, days), close_prices)]
    })

    print("ğŸ“‹ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤ºåŠŸèƒ½ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦ç½‘ç»œè¿æ¥ï¼‰")
    return df

def plot_fund_performance(df: pd.DataFrame, fund_code: str, days: int = 30, save_path: str = None):
    """
    ç»˜åˆ¶åŸºé‡‘æ¶¨è·Œå¹…æŠ˜çº¿å›¾

    :param df: åŒ…å«åŸºé‡‘æ•°æ®çš„DataFrame
    :param fund_code: åŸºé‡‘ä»£ç 
    :param days: äº¤æ˜“æ—¥å¤©æ•°
    :param save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
    """
    # è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
    try:
        # å°è¯•ä½¿ç”¨ç³»ç»Ÿæ”¯æŒçš„ä¸­æ–‡å­—ä½“
        zh_fonts = ['PingFang SC', 'Hiragino Sans GB', 'STHeiti', 'Microsoft YaHei', 'SimHei', 'DejaVu Sans']
        for font_name in zh_fonts:
            if font_name in [f.name for f in fm.fontManager.ttflist]:
                plt.rcParams['font.sans-serif'] = [font_name, 'DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·
                break
    except:
        # å¦‚æœå­—ä½“è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
        pass

    plt.figure(figsize=(12, 6))
    plt.plot(df['æ—¥æœŸ'], df['æ¶¨è·Œå¹…'], marker='o', linestyle='-', linewidth=2, markersize=4)

    # è®¾ç½®å›¾è¡¨æ ‡é¢˜å’Œæ ‡ç­¾
    plt.title(f'QDIIåŸºé‡‘ {fund_code} è¿‘{days}ä¸ªäº¤æ˜“æ—¥æ¶¨è·Œå¹…', fontsize=16, fontweight='bold')
    plt.xlabel('æ—¥æœŸ', fontsize=12)
    plt.ylabel('æ¶¨è·Œå¹… (%)', fontsize=12)

    # è®¾ç½®xè½´æ—¥æœŸæ ¼å¼
    plt.gcf().autofmt_xdate()

    # æ·»åŠ ç½‘æ ¼
    plt.grid(True, alpha=0.3)

    # æ·»åŠ é›¶çº¿
    plt.axhline(y=0, color='r', linestyle='--', alpha=0.7)

    # åœ¨æœ€åä¸€ä¸ªæ•°æ®ç‚¹æ ‡æ³¨æ•°å€¼
    last_date = df['æ—¥æœŸ'].iloc[-1]
    last_change = df['æ¶¨è·Œå¹…'].iloc[-1]
    plt.annotate(f'{last_change:.2f}%',
                xy=(last_date, last_change),
                xytext=(10, 10),
                textcoords='offset points',
                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),
                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))

    plt.tight_layout()

    # ä¿å­˜æˆ–æ˜¾ç¤ºå›¾ç‰‡
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
    else:
        plt.show()

def analyze_fund_performance(df: pd.DataFrame, fund_code: str, days: int):
    """
    åˆ†æåŸºé‡‘è¡¨ç°å¹¶è¾“å‡ºç»Ÿè®¡ä¿¡æ¯

    :param df: åŒ…å«åŸºé‡‘æ•°æ®çš„DataFrame
    :param fund_code: åŸºé‡‘ä»£ç 
    :param days: äº¤æ˜“æ—¥å¤©æ•°
    """
    print(f"\nğŸ“Š QDIIåŸºé‡‘ {fund_code} è¿‘{days}ä¸ªäº¤æ˜“æ—¥è¡¨ç°åˆ†æ:")
    print("=" * 50)

    # æ˜¾ç¤ºæœ€è¿‘10æ¡æ•°æ®
    print(f"\næœ€è¿‘10ä¸ªäº¤æ˜“æ—¥æ•°æ®:")
    print(df[['æ—¥æœŸ', 'æ”¶ç›˜', 'æ¶¨è·Œå¹…']].head(10).to_string(index=False))

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_return = df['æ¶¨è·Œå¹…'].sum()
    avg_daily_return = df['æ¶¨è·Œå¹…'].mean()
    max_gain = df['æ¶¨è·Œå¹…'].max()
    max_loss = df['æ¶¨è·Œå¹…'].min()
    positive_days = len(df[df['æ¶¨è·Œå¹…'] > 0])
    volatility = df['æ¶¨è·Œå¹…'].std()

    print(f"\nğŸ“ˆ åŸºç¡€ç»Ÿè®¡:")
    print(f"æ€»æ”¶ç›Š: {total_return:.2f}%")
    print(f"æ—¥å‡æ”¶ç›Š: {avg_daily_return:.2f}%")
    print(f"æœ€å¤§å•æ—¥æ¶¨å¹…: {max_gain:.2f}%")
    print(f"æœ€å¤§å•æ—¥è·Œå¹…: {max_loss:.2f}%")
    print(f"æ³¢åŠ¨ç‡: {volatility:.2f}%")
    print(f"ä¸Šæ¶¨å¤©æ•°: {positive_days}/{days} ({positive_days/days*100:.1f}%)")

    # ä½¿ç”¨ä¸“ä¸šçš„æŠ•èµ„å»ºè®®æ¨¡å—ï¼ˆç‹¬ç«‹çš„è¯¦ç»†åˆ†æå’Œå»ºè®®ï¼‰
    quick_advice(df, fund_code)


def save_to_database(df: pd.DataFrame, fund_code: str):
    """
    å°†åŸºé‡‘æ•°æ®ä¿å­˜åˆ°MySQLæ•°æ®åº“

    :param df: åŒ…å«åŸºé‡‘æ•°æ®çš„DataFrame
    :param fund_code: åŸºé‡‘ä»£ç 
    """
    connection = None
    try:
        # è¿æ¥æ•°æ®åº“
        connection = pymysql.connect(**database_config.MYSQL_CONFIG)

        with connection.cursor() as cursor:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
            cursor.execute(database_config.CREATE_TABLE_SQL)

            # å‡†å¤‡æ’å…¥æ•°æ®çš„SQL
            insert_sql = """
            INSERT INTO qdii_fund_data 
            (fund_code, trade_date, open_price, close_price, high_price, low_price, change_percent, volume, turnover)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE 
            open_price = VALUES(open_price),
            close_price = VALUES(close_price),
            high_price = VALUES(high_price),
            low_price = VALUES(low_price),
            change_percent = VALUES(change_percent),
            volume = VALUES(volume),
            turnover = VALUES(turnover),
            updated_time = CURRENT_TIMESTAMP
            """

            # å‡†å¤‡æ•°æ®ï¼ˆä½¿ç”¨ä¸­æ–‡åˆ—åï¼‰
            data_to_insert = []
            for _, row in df.iterrows():
                data_to_insert.append((
                    fund_code,
                    row['æ—¥æœŸ'].date() if hasattr(row['æ—¥æœŸ'], 'date') else row['æ—¥æœŸ'],
                    row['å¼€ç›˜'],
                    row['æ”¶ç›˜'],
                    row['æœ€é«˜'],
                    row['æœ€ä½'],
                    row['æ¶¨è·Œå¹…'],
                    row['æˆäº¤é‡'],
                    row['æˆäº¤é¢']
                ))

            # æ‰¹é‡æ’å…¥æ•°æ®
            cursor.executemany(insert_sql, data_to_insert)
            connection.commit()

            print(f"âœ… æˆåŠŸä¿å­˜ {len(data_to_insert)} æ¡æ•°æ®åˆ°æ•°æ®åº“")

    except Error as e:
        print(f"âŒ æ•°æ®åº“é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®åº“é…ç½®å’Œè¿æ¥")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        if connection and connection.open:
            connection.close()

def main():
    """ä¸»å‡½æ•° - ç›´æ¥ä»£ç è°ƒç”¨ç¤ºä¾‹"""
    try:
        # ç›´æ¥åœ¨ä»£ç ä¸­è®¾ç½®å‚æ•°
        fund_code = "513100"  # çº³æ–¯è¾¾å…‹100ETFï¼Œå¯ä»¥æ”¹æˆå…¶ä»–ä»£ç 
        days = 30             # åˆ†ææœ€è¿‘30ä¸ªäº¤æ˜“æ—¥
        save_path = None      # å›¾ç‰‡ä¿å­˜è·¯å¾„ï¼Œè®¾ä¸ºNoneåˆ™æ˜¾ç¤ºä¸ä¿å­˜

        # è·å–åŸºé‡‘æ•°æ®ï¼ˆè¿”å›å®Œæ•´æ•°æ®å’Œæ–°è·å–çš„æ•°æ®ï¼‰
        print(f"æ­£åœ¨è·å–åŸºé‡‘ {fund_code} è¿‘{days}ä¸ªäº¤æ˜“æ—¥æ•°æ®...")
        df, new_data = get_qdii_fund_data(fund_code, days)

        # åˆ†æåŸºé‡‘è¡¨ç°
        analyze_fund_performance(df, fund_code, days)

        # åªä¿å­˜æ–°è·å–çš„æ•°æ®åˆ°æ•°æ®åº“
        if not new_data.empty:
            print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ {len(new_data)} æ¡æ–°æ•°æ®åˆ°æ•°æ®åº“...")
            save_to_database(new_data, fund_code)
        else:
            print(f"\nâœ… æ— éœ€ä¿å­˜ï¼Œæ•°æ®åº“å·²æ˜¯æœ€æ–°")

        # ç»˜åˆ¶å›¾è¡¨
        print(f"\nğŸ¨ æ­£åœ¨ç”Ÿæˆæ¶¨è·Œå¹…æŠ˜çº¿å›¾...")
        plot_fund_performance(df, fund_code, days, save_path)

    except ValueError as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("\nğŸ’¡ å¸¸è§QDIIåŸºé‡‘ä»£ç ç¤ºä¾‹:")
        print("   - 513100: çº³æ–¯è¾¾å…‹100ETF")
        print("   - 513500: æ ‡æ™®500ETF")
        print("   - 159920: æ’ç”ŸETF")
        print("   - 513050: ä¸­æ¦‚äº’è”ETF")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä»£ç†è®¾ç½®ï¼Œæˆ–ç¨åé‡è¯•")

if __name__ == "__main__":
    main()